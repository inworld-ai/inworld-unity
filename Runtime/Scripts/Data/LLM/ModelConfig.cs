/*************************************************************************************************
 * Copyright 2022-2024 Theai, Inc. dba Inworld AI
 *
 * Use of this source code is governed by the Inworld.ai Software Development Kit License Agreement
 * that can be found in the LICENSE.md file or at https://www.inworld.ai/sdk-license
 *************************************************************************************************/

using Newtonsoft.Json;
using Newtonsoft.Json.Converters;
using System;
using System.Collections.Generic;
using UnityEngine;


namespace Inworld.LLM.ModelConfig
{
	// Modify the likelihood of specified tokens appearing in the completion.
	[Serializable]
	public class LogitBias 
	{
		// Id of the token.
		public string token_id;
		// Bias value from -100 to 100.
		[Range(-100, 100)] public int bias_value;
	}
	
	// Function to call.
	[Serializable]
	public class FunctionCall 
	{
		// The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes,
		// with a maximum length of 64.
		public string name;
		// A description of what the function does, used by the model to choose when and how to call the
		// function.
		[JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
		public string description;
		// The parameters the functions accepts, described as a JSON Schema object.
		
		[JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
		public string properties;
	}
	
	// A tool the model may call.
	[Serializable]
	public class Tool 
	{
		// Function to call.
		public FunctionCall function_call;
	}
	
	// Controls which (if any) function is called by the model.
	[Serializable]
	public class ToolChoice
	{

	}

	[Serializable]
	public class TextToolChoice : ToolChoice
	{
		[JsonConverter(typeof(StringEnumConverter))]
		public Kind text;
	}
	
	[Serializable]
	public class FunctionToolChoice : ToolChoice
	{
		// YAN: Noticed that in this class, the description has to be null.
		public Tool @object;
	}
	
	// Configuration on how to perform text generation e2e.
	[Serializable]
	public class TextGenerationConfig 
	{
	  // Positive values penalize new tokens based on their existing frequency in the text so far, decreasing
	  // the model's likelihood to repeat the same line verbatim. Defaults to 0.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public float frequency_penalty;

	  // Modify the likelihood of specified tokens appearing in the completion.
	  // Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will
	  // vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100
	  // or 100 should result in a ban or exclusive selection of the relevant token.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public List<LogitBias> logit_bias;

	  // Maximum number of output tokens allowed to generate. The total length of input tokens and generated
	  // tokens is limited by the model's context length. Defaults to inf.
	  // YAN: However, the Gpt4o's max token is 2500. Let's not exceed unless you know your models capacity.
	  public int max_tokens = 2500;

	  // How many choices to generate for each input message. Defaults to 1.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public int n = 1;

	  // Positive values penalize new tokens based on whether they appear in the text so far, increasing the
	  // model's likelihood to talk about new topics. Defaults to 0.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public float presence_penalty;

	  // YAN: If you've set the related tokens, such as "Apple", whenever the character generates till "Apple" it'll be stopped.
	  // Up to 4 sequences where the API will stop generating further tokens.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public List<string> stop;

	  // If set, partial message deltas will be sent. Defaults to false.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public bool stream;

	  // What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more
	  // random, while lower values like 0.2 will make it more focused and deterministic. Defaults to 1.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  [Range(0,2)] public float temperature;

	  // An alternative to sampling with temperature, called nucleus sampling, where the model considers the
	  // results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability
	  // mass are considered. Defaults to 1.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  [Range(0,1)] float top_p;

	  // Float that penalizes new tokens based on whether they appear in the prompt and the
	  // generated text so far. Values > 1 encourage the model to use new tokens, while
	  // values < 1 encourage the model to repeat tokens. The value must be strictly
	  // positive. Defaults to 1 (no penalty).
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public float repetition_penalty;

	  // Random seed for decoding.
	  [JsonProperty(NullValueHandling=NullValueHandling.Ignore)]
	  public int seed;
	}
}
